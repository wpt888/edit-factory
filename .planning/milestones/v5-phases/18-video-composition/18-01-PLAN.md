---
phase: 18-video-composition
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/services/product_video_compositor.py
autonomous: true
requirements:
  - COMP-01
  - COMP-06

must_haves:
  truths:
    - "A product image animates with Ken Burns zoom/pan motion for the full video duration"
    - "User can set video duration to 15, 30, 45, or 60 seconds and the output matches"
    - "zoompan vs simple-scale benchmark is documented with actual timings from the dev machine"
  artifacts:
    - path: "app/services/product_video_compositor.py"
      provides: "Core FFmpeg composition service with Ken Burns animation and duration control"
      contains: "compose_product_video"
  key_links:
    - from: "app/services/product_video_compositor.py"
      to: "FFmpeg subprocess"
      via: "subprocess.run with filter_complex"
      pattern: "subprocess\\.run.*ffmpeg"
    - from: "app/services/product_video_compositor.py"
      to: "app/services/textfile_helper.py"
      via: "import build_drawtext_filter"
      pattern: "from app\\.services\\.textfile_helper import"
---

<objective>
Create the product_video_compositor.py service that generates a portrait MP4 from a product image using FFmpeg zoompan Ken Burns animation with configurable duration. Run a timed benchmark comparing zoompan vs simple-scale to document performance for Phase 21 batch decisions.

Purpose: This is the core video generation engine for product videos. Without it, no product video can be created. The benchmark result determines whether batch generation (Phase 21) can use Ken Burns or must default to simple-scale.
Output: `app/services/product_video_compositor.py` with `compose_product_video()` function and benchmark results logged to STATE.md.
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-video-composition/18-RESEARCH.md
@app/services/textfile_helper.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create product_video_compositor.py with Ken Burns animation and duration control</name>
  <files>app/services/product_video_compositor.py</files>
  <action>
Create `app/services/product_video_compositor.py` with:

1. **Imports and constants:**
   - `import subprocess, time, logging, tempfile, os` from stdlib
   - `from pathlib import Path`
   - `from dataclasses import dataclass`
   - `from app.services.textfile_helper import build_drawtext_filter, build_multi_drawtext, cleanup_textfiles`
   - Constants: `W_OUT=1080`, `H_OUT=1920`, `FPS=25`, `W_LARGE=4320` (4x pre-scale for smooth zoompan)
   - `VALID_DURATIONS = {15, 30, 45, 60}`

2. **`CompositorConfig` dataclass:**
   ```python
   @dataclass
   class CompositorConfig:
       duration_s: int = 30
       cta_text: str = "Comanda acum!"
       fps: int = 25
       use_zoompan: bool = True  # False = simple-scale (faster, for batch)
   ```

3. **`_calculate_zoompan_params(duration_s, fps)` function:**
   - Returns dict with `n_frames`, `z_inc`, `z_end`
   - Zoom from 1.0 to 1.5 over the full duration
   - `n_frames = fps * duration_s`
   - `z_inc = 0.5 / n_frames`
   - `z_end = 1.5`

4. **`_build_scale_pad_filter(use_zoompan)` function:**
   - When `use_zoompan=True`: `scale={W_LARGE}:-1:force_original_aspect_ratio=decrease,pad={W_LARGE}:{W_LARGE*H_OUT//W_OUT}:(ow-iw)/2:(oh-ih)/2:black`
   - When `use_zoompan=False`: `scale={W_OUT}:{H_OUT}:force_original_aspect_ratio=decrease,pad={W_OUT}:{H_OUT}:(ow-iw)/2:(oh-ih)/2:black`

5. **`_build_zoompan_filter(duration_s, fps)` function:**
   - Uses `_calculate_zoompan_params` to get z_inc and n_frames
   - Returns: `zoompan=z='min(zoom+{z_inc:.6f},1.5)':x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)':d={n_frames}:s={W_OUT}x{H_OUT}:fps={fps}`

6. **`compose_product_video(image_path, output_path, product, config)` function:**
   - Validates `config.duration_s in VALID_DURATIONS`, raises ValueError if not
   - Creates `output_path.parent` directory if missing
   - Builds text overlays using `_build_text_overlays(product, config.cta_text)` — for now, just product name at position y=160:
     ```python
     overlays = [{'text': product.get('title', 'Product')[:60], 'fontsize': 48, 'fontcolor': 'white', 'x': '40', 'y': '160', 'box': True, 'boxcolor': 'black@0.6', 'boxborderw': 8}]
     ```
     (Plan 18-02 adds sale badge, full price overlays, CTA — this plan just needs the compositor working with basic text)
   - Builds FFmpeg command:
     - Input: `-loop 1 -framerate {fps} -i {image_path}`
     - If `use_zoompan=True`: `-vf` with scale+pad(4x) + zoompan + text overlays
     - If `use_zoompan=False`: `-vf` with scale+pad(1x) + text overlays (no zoompan)
     - Output: `-t {duration_s} -c:v libx264 -preset veryfast -crf 20 -pix_fmt yuv420p {output_path}`
   - Note: Use `-vf` (not `-filter_complex`) for this plan since there is no second input (badge overlay). Plan 18-02 will add `filter_complex` when badge is needed.
   - Runs subprocess with `timeout=600`, logs stderr on failure, raises RuntimeError
   - Cleans up textfile temp files in `finally` block

7. **`benchmark_zoompan(image_path, duration_s=30)` function:**
   - Runs simple-scale encode to `/tmp/bench_simple.mp4`, times it
   - Runs zoompan encode to `/tmp/bench_zoompan.mp4`, times it
   - Calculates slowdown factor
   - Logs results at INFO level: "Benchmark: simple_scale={X:.1f}s, zoompan={Y:.1f}s, slowdown={Z:.1f}x"
   - Returns dict with `simple_scale_s`, `zoompan_s`, `slowdown_factor`
   - Cleans up bench files after timing

All text overlays MUST use `build_drawtext_filter`/`build_multi_drawtext` from textfile_helper.py. Never use `text=` directly in FFmpeg filter strings for product content.
  </action>
  <verify>
Run a quick smoke test: create a small test image, call `compose_product_video` with `use_zoompan=False` (fast) for 15 seconds, verify the output MP4 exists and has non-zero size:
```bash
cd "/mnt/c/OBSID SRL/n8n/edit_factory"
python -c "
from pathlib import Path
from app.services.product_video_compositor import compose_product_video, CompositorConfig
import subprocess
# Create a test image (solid blue 800x800)
subprocess.run(['ffmpeg', '-y', '-f', 'lavfi', '-i', 'color=c=blue:s=800x800', '-vframes', '1', '/tmp/test_product.jpg'], capture_output=True, check=True)
product = {'title': 'Test Product Name', 'brand': 'TestBrand', 'raw_price_str': '99.99 RON'}
cfg = CompositorConfig(duration_s=15, use_zoompan=False)
compose_product_video(Path('/tmp/test_product.jpg'), Path('/tmp/test_output.mp4'), product, cfg)
import os
size = os.path.getsize('/tmp/test_output.mp4')
print(f'Output size: {size} bytes')
assert size > 10000, 'Output too small'
print('PASS: Simple-scale composition works')
"
```
  </verify>
  <done>
`app/services/product_video_compositor.py` exists with `compose_product_video()` and `benchmark_zoompan()` functions. Simple-scale composition produces a valid MP4 from a test image. Zoompan composition uses 4x pre-scale for smooth motion.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run zoompan benchmark and document results in STATE.md</name>
  <files>app/services/product_video_compositor.py</files>
  <action>
Run the benchmark function on the dev machine with a real product-like image (800x800 JPEG, simulating a typical product feed image) for 30 seconds:

```python
from pathlib import Path
from app.services.product_video_compositor import benchmark_zoompan
import subprocess

# Create a realistic test image (800x800, some visual content)
subprocess.run(['ffmpeg', '-y', '-f', 'lavfi', '-i',
    'color=c=white:s=800x800,drawtext=text=Product:fontsize=72:fontcolor=black:x=(w-text_w)/2:y=(h-text_h)/2',
    '-vframes', '1', '/tmp/bench_product.jpg'], capture_output=True, check=True)

results = benchmark_zoompan(Path('/tmp/bench_product.jpg'), duration_s=30)
print(f"Simple scale: {results['simple_scale_s']:.1f}s")
print(f"Zoompan: {results['zoompan_s']:.1f}s")
print(f"Slowdown: {results['slowdown_factor']:.1f}x")
```

After running, update STATE.md `### Decisions` section to add the benchmark result:
```
- [18-01]: zoompan benchmark on WSL dev machine: simple_scale={X}s, zoompan={Y}s, {Z}x slowdown for 30s portrait video. {Decision about batch default based on result — if zoompan > 120s for 30s video, batch defaults to simple-scale; otherwise zoompan is viable for batch.}
```

Also update STATE.md `### Blockers/Concerns` to resolve the "v5 Phase 18 risk" entry by replacing it with the actual benchmark result.
  </action>
  <verify>
Verify STATE.md contains the benchmark decision:
```bash
grep -c "zoompan benchmark" .planning/STATE.md
```
Should return 1.

Verify the benchmark actually ran by checking the log output contains timing numbers.
  </verify>
  <done>
zoompan benchmark has run on the dev machine. STATE.md updated with actual timing results and a decision about whether Phase 21 batch should default to zoompan or simple-scale. The "v5 Phase 18 risk" blocker is resolved with real data.
  </done>
</task>

</tasks>

<verification>
1. `app/services/product_video_compositor.py` exists and imports correctly
2. `compose_product_video()` produces a valid MP4 from a test image with both `use_zoompan=True` and `use_zoompan=False`
3. Duration parameter controls output length (15s input produces ~15s video)
4. All text overlays use `textfile=` pattern (no `text=` in filter strings)
5. Benchmark results documented in STATE.md with batch decision
</verification>

<success_criteria>
- Product image converts to portrait MP4 with Ken Burns zoom animation
- Duration control works for 15/30/45/60 second values
- Benchmark timing is documented with a clear decision for Phase 21 batch default
- No new Python dependencies introduced
</success_criteria>

<output>
After completion, create `.planning/phases/18-video-composition/18-01-SUMMARY.md`
</output>
