---
phase: 21-batch-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/api/product_generate_routes.py
autonomous: true
requirements:
  - BATCH-02
  - BATCH-03

must_haves:
  truths:
    - "POST /products/batch-generate accepts a list of product_ids and returns a batch_id immediately"
    - "Each product in the batch is processed sequentially with its own try/except — a failure in product N does not prevent product N+1 from processing"
    - "GET /products/batch/{batch_id}/status returns per-product status including progress, state, and error message for each product in the batch"
    - "Batch state persists in Supabase jobs table so navigating away and returning preserves progress"
  artifacts:
    - path: "app/api/product_generate_routes.py"
      provides: "BatchGenerateRequest model, batch-generate endpoint, batch status endpoint, _batch_generate_task with per-product error isolation"
      contains: "class BatchGenerateRequest"
  key_links:
    - from: "app/api/product_generate_routes.py::batch_generate_products"
      to: "app/api/product_generate_routes.py::_generate_product_video_task"
      via: "sequential loop calling existing single-product pipeline per product"
      pattern: "_generate_product_video_task"
    - from: "app/api/product_generate_routes.py::get_batch_status"
      to: "app/services/job_storage.py::get_job"
      via: "reads batch job record and merges child job states"
      pattern: "job_storage\\.get_job"
---

<objective>
Add batch product video generation backend: a POST endpoint that accepts multiple product IDs, dispatches a sequential background task with per-product error isolation, and a GET endpoint that returns aggregated per-product status for polling.

Purpose: Enable generating videos for multiple products in one action (BATCH-02) with one failure not killing the batch (BATCH-03).
Output: Two new endpoints in product_generate_routes.py — POST /batch-generate and GET /batch/{batch_id}/status.
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/21-batch-generation/21-RESEARCH.md
@app/api/product_generate_routes.py
@app/services/job_storage.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add BatchGenerateRequest model and POST /batch-generate endpoint</name>
  <files>app/api/product_generate_routes.py</files>
  <action>
Add to product_generate_routes.py:

1. **BatchGenerateRequest** Pydantic model:
   - `product_ids: list[str]` — validated: min 2, max 50 items
   - Same fields as ProductGenerateRequest: voiceover_mode (default "quick"), tts_provider (default "edge"), voice_id, ai_provider, duration_s, encoding_preset, voiceover_template, cta_text, enable_denoise, enable_sharpen, enable_color_correction
   - Add a Pydantic validator that raises ValueError if len(product_ids) < 2 or > 50

2. **POST /batch-generate** endpoint:
   - Depends on get_profile_context for auth
   - Creates a batch_id (uuid4)
   - For each product_id, creates a `product_job` dict: `{"product_id": pid, "job_id": str(uuid4()), "title": "", "status": "queued", "progress": "0", "error": None}`
   - Fetches product titles from Supabase in one query: `supabase.table("products").select("id, title").in_("id", request.product_ids).execute()` — populate the title field in each product_job dict
   - Calls `job_storage.create_job({"job_id": batch_id, "job_type": "batch_product_video", "status": "processing", "progress": "0", "product_jobs": product_jobs, "total": len(product_jobs), "completed": 0, "failed": 0}, profile_id=profile.profile_id)`
   - Dispatches ONE background task: `background_tasks.add_task(_batch_generate_task, batch_id=batch_id, product_jobs=product_jobs, profile_id=profile.profile_id, request=request)`
   - Returns `{"batch_id": batch_id, "total": len(product_jobs)}`

3. **_batch_generate_task** async function:
   - Sequential `for product_job in product_jobs:` loop
   - Before each product: update batch record to set this product's status to "processing" via a helper `_update_batch_product_status(batch_id, product_id, status, job_storage, profile_id, error=None)`
   - Inside try: Create child job via `job_storage.create_job(...)` with `job_type="product_video"`, then call `await _generate_product_video_task(job_id=child_job_id, product_id=pid, profile_id=profile_id, request=single_request)` where `single_request` is a `ProductGenerateRequest` constructed from the batch request fields
   - After try: Check child job status via `job_storage.get_job(child_job_id)`. If completed, update batch product to "completed". If failed/other, update to "failed" with error.
   - `except Exception as exc:` — NEVER re-raise. Log with `logger.error(...)`, call `_update_batch_product_status(batch_id, pid, "failed", job_storage, profile_id, str(exc))`
   - After loop: call `_finalize_batch(batch_id, job_storage, profile_id)` which counts completed/failed and sets batch status to "completed" (all done) or "completed_with_errors" (some failed)

4. **Helper _update_batch_product_status**:
   - Reads batch job, finds product_job by product_id in the product_jobs list, updates its status/progress/error, writes back via `job_storage.update_job(batch_id, updated_data, profile_id)`

5. **Helper _finalize_batch**:
   - Reads batch, counts completed/failed from product_jobs, updates batch status and completed/failed counts
  </action>
  <verify>
Review the code to confirm:
- BatchGenerateRequest has product_ids list with min/max validation
- POST /batch-generate creates batch job and dispatches background task
- _batch_generate_task has `except Exception` that never re-raises
- _update_batch_product_status correctly mutates the product_jobs list in the batch record
  </verify>
  <done>POST /batch-generate endpoint accepts product_ids list, creates batch record in JobStorage, and dispatches sequential background task with per-product error isolation</done>
</task>

<task type="auto">
  <name>Task 2: Add GET /batch/{batch_id}/status polling endpoint</name>
  <files>app/api/product_generate_routes.py</files>
  <action>
Add to product_generate_routes.py:

1. **GET /batch/{batch_id}/status** endpoint:
   - Depends on get_profile_context for auth
   - Reads batch record: `batch = job_storage.get_job(batch_id)`
   - If not found, raise HTTPException(404, "Batch not found")
   - For each product_job in `batch["product_jobs"]`:
     - Read child job: `child = job_storage.get_job(pj["job_id"]) or {}`
     - Build product status dict: `{"product_id": pj["product_id"], "job_id": pj["job_id"], "title": pj.get("title", ""), "status": child.get("status", pj.get("status", "queued")), "progress": child.get("progress", "0"), "error": child.get("error"), "result": child.get("result")}`
   - Compute aggregates: `completed = sum(1 for p in statuses if p["status"] == "completed")`, similarly for failed
   - Determine overall batch status: "completed" if (completed + failed) == total, else "processing"
   - Return: `{"batch_id": batch_id, "status": overall_status, "total": total, "completed": completed, "failed": failed, "product_jobs": product_statuses}`

2. Verify the endpoint handles edge cases:
   - Batch with 0 completed products (all still queued) returns status "processing"
   - Batch where all products are done (mix of completed/failed) returns status "completed"
   - Child job not found in storage falls back to the status stored in batch record's product_jobs list
  </action>
  <verify>
Manually verify by reading the endpoint code that:
- It reads from job_storage.get_job for both batch and child jobs
- Returns the correct JSON shape with product_jobs array
- Falls back gracefully when child job is not found
  </verify>
  <done>GET /batch/{batch_id}/status returns per-product progress with status, progress percentage, error message, and result for each product in the batch</done>
</task>

</tasks>

<verification>
1. product_generate_routes.py contains BatchGenerateRequest with product_ids validation (2-50)
2. POST /batch-generate creates batch job record and dispatches _batch_generate_task
3. _batch_generate_task loops sequentially with `except Exception` that never re-raises
4. GET /batch/{batch_id}/status returns aggregated per-product status by merging batch record with child job records
5. No new files created — all changes in existing product_generate_routes.py
</verification>

<success_criteria>
- Batch dispatch endpoint creates N child jobs and processes them sequentially
- Per-product error isolation confirmed: except block catches all exceptions and continues to next product
- Batch status endpoint returns per-product state array with progress, status, error fields
- Batch state persists in Supabase jobs table (navigate-away-and-return works)
</success_criteria>

<output>
After completion, create `.planning/phases/21-batch-generation/21-01-SUMMARY.md`
</output>
