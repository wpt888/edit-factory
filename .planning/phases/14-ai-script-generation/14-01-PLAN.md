---
phase: 14-ai-script-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/services/script_generator.py
  - app/api/script_routes.py
  - app/main.py
  - app/config.py
  - requirements.txt
autonomous: true
must_haves:
  truths:
    - "POST /api/v1/scripts/generate accepts idea, context, variant_count, provider and returns N TTS-safe script strings"
    - "GET /api/v1/scripts/keywords returns unique segment keywords from editai_segments for the current profile"
    - "Script generator sends segment keywords to AI so it writes keyword-aware scripts"
    - "Gemini and Claude (Anthropic) are both supported as AI providers"
    - "Generated scripts are TTS-safe: plain text, proper punctuation, no emojis, no stage directions"
  artifacts:
    - path: "app/services/script_generator.py"
      provides: "AI script generation with Gemini and Claude providers"
      exports: ["ScriptGenerator", "get_script_generator"]
    - path: "app/api/script_routes.py"
      provides: "Script generation API endpoints"
      exports: ["router"]
    - path: "requirements.txt"
      provides: "anthropic SDK dependency"
      contains: "anthropic"
  key_links:
    - from: "app/api/script_routes.py"
      to: "app/services/script_generator.py"
      via: "get_script_generator() singleton call"
      pattern: "from app\\.services\\.script_generator import"
    - from: "app/api/script_routes.py"
      to: "editai_segments table"
      via: "Supabase query for unique keywords"
      pattern: "editai_segments.*keywords"
    - from: "app/main.py"
      to: "app/api/script_routes.py"
      via: "include_router mount"
      pattern: "script_routes"
---

<objective>
Create the backend AI script generation service and API routes for Phase 14.

Purpose: Enable AI-powered script generation using Gemini or Claude, with segment keyword awareness for downstream video matching. This is the core backend for the script-first pipeline.

Output: Working API that generates N TTS-ready script variants from user idea/context, using available segment keywords to guide AI output.
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Existing patterns to follow
@app/services/gemini_analyzer.py — Gemini API usage pattern (google-genai client)
@app/services/elevenlabs_tts.py — Service class pattern (singleton factory)
@app/api/segments_routes.py — Supabase segment/keyword query patterns, ProfileContext usage
@app/config.py — Settings pattern for API keys
@app/main.py — Router mounting pattern
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AI script generation service with dual-provider support</name>
  <files>app/services/script_generator.py, app/config.py, requirements.txt</files>
  <action>
    1. Add `anthropic>=0.40.0` to requirements.txt (after the Google Gemini section, add a comment `# Anthropic Claude AI`).

    2. Add `anthropic_api_key: str = ""` to `app/config.py` Settings class (after elevenlabs settings).

    3. Create `app/services/script_generator.py` with:

    **ScriptGenerator class:**
    - `__init__(self, gemini_api_key, anthropic_api_key, gemini_model)` — store keys, lazy-init clients
    - `generate_scripts(self, idea: str, context: str, keywords: List[str], variant_count: int, provider: str) -> List[str]`
      - Validates provider is "gemini" or "claude"
      - Builds a prompt that includes:
        - The user's idea and product context
        - Available segment keywords (so AI writes scripts that reference them naturally)
        - TTS-safe template rules: plain text only, proper punctuation, no emojis, no stage directions, no markdown, no brackets, each script is a self-contained voiceover narration
        - Number of variants requested
        - Each variant should be a unique angle/approach to the same idea
        - Target duration hint: ~30-60 seconds when spoken (~75-150 words per script)
      - Calls `_generate_with_gemini()` or `_generate_with_claude()` based on provider
      - Parses response to extract individual script variants
      - Validates each script is TTS-safe (strip any accidental emojis, markdown, brackets)
      - Returns `List[str]` of clean script texts

    **_generate_with_gemini(self, prompt: str) -> str:**
    - Uses `google.genai.Client(api_key=...)` following existing gemini_analyzer.py pattern
    - Calls `client.models.generate_content(model=self.gemini_model, contents=prompt)`
    - Returns raw text response

    **_generate_with_claude(self, prompt: str) -> str:**
    - Uses `anthropic.Anthropic(api_key=...)` client
    - Calls `client.messages.create(model="claude-sonnet-4-20250514", max_tokens=4096, messages=[{"role": "user", "content": prompt}])`
    - Returns raw text response from `response.content[0].text`

    **_parse_scripts(self, raw_response: str, variant_count: int) -> List[str]:**
    - Splits response into individual scripts (use delimiter like "---" or numbered sections)
    - Strips whitespace, removes any markdown formatting
    - Returns list of clean scripts

    **_sanitize_for_tts(self, text: str) -> str:**
    - Removes emojis (regex for Unicode emoji ranges)
    - Removes markdown formatting (*bold*, _italic_, #headers, [links])
    - Removes stage directions in brackets [pause], (whisper), etc.
    - Preserves proper punctuation (periods, commas, question marks, exclamation)
    - Collapses multiple whitespace/newlines into single spaces
    - Returns clean TTS-ready text

    **Singleton factory:**
    ```python
    _script_generator = None
    def get_script_generator() -> ScriptGenerator:
        global _script_generator
        if _script_generator is None:
            settings = get_settings()
            _script_generator = ScriptGenerator(
                gemini_api_key=settings.gemini_api_key,
                anthropic_api_key=settings.anthropic_api_key,
                gemini_model=settings.gemini_model
            )
        return _script_generator
    ```

    **Prompt template** should instruct AI to:
    - Generate exactly N script variants separated by "---SCRIPT---" delimiter
    - Each script is a standalone voiceover narration for a social media video (reel/TikTok/Short)
    - Use the provided keywords naturally in the narration (don't force every keyword)
    - Keep each script 75-150 words (30-60 seconds when spoken)
    - Write in the same language as the user's idea/context
    - NO emojis, NO hashtags, NO stage directions, NO markdown
    - Proper punctuation for natural TTS pauses

    **Error handling:**
    - If provider key is missing, raise ValueError with clear message
    - If AI call fails, log error and raise HTTPException-compatible error
    - If parsing returns fewer scripts than requested, log warning but return what was parsed
  </action>
  <verify>
    - `python -c "from app.services.script_generator import ScriptGenerator, get_script_generator; print('Import OK')"` succeeds
    - `python -c "from app.config import get_settings; s = get_settings(); print(f'anthropic_api_key field exists: {hasattr(s, \"anthropic_api_key\")}')"` prints True
    - `grep 'anthropic' requirements.txt` shows the dependency
  </verify>
  <done>
    ScriptGenerator service exists with generate_scripts() method supporting both Gemini and Claude providers. Prompt includes segment keywords for keyword-aware scripts. TTS sanitization strips emojis, markdown, stage directions. Singleton factory function available.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create script generation API routes and mount in app</name>
  <files>app/api/script_routes.py, app/main.py</files>
  <action>
    1. Create `app/api/script_routes.py` with:

    **Imports and setup:**
    - Follow segments_routes.py pattern: logging, APIRouter, ProfileContext, Depends
    - `router = APIRouter(prefix="/scripts", tags=["scripts"])`
    - Lazy Supabase client (same pattern as segments_routes.py)

    **Pydantic models:**
    ```python
    class ScriptGenerateRequest(BaseModel):
        idea: str                           # User's video idea/concept
        context: str = ""                   # Product/brand context
        variant_count: int = 3              # Number of script variants (1-10)
        provider: str = "gemini"            # "gemini" or "claude"

    class ScriptGenerateResponse(BaseModel):
        scripts: List[str]                  # Generated script texts
        provider: str                       # Which AI provider was used
        keyword_count: int                  # How many keywords were sent to AI
    ```

    **Endpoints:**

    `POST /scripts/generate` — Generate script variants
    - Depends on `get_profile_context` for profile isolation
    - Validates `variant_count` is 1-10, `provider` is "gemini" or "claude"
    - Fetches unique keywords from `editai_segments` table for current profile:
      ```python
      result = supabase.table("editai_segments")\
          .select("keywords")\
          .eq("profile_id", profile.profile_id)\
          .execute()
      # Flatten and deduplicate keywords
      all_keywords = set()
      for seg in result.data:
          for kw in (seg.get("keywords") or []):
              all_keywords.add(kw)
      unique_keywords = sorted(all_keywords)
      ```
    - Calls `get_script_generator().generate_scripts(idea, context, unique_keywords, variant_count, provider)`
    - Returns ScriptGenerateResponse with scripts, provider used, and keyword count
    - Error handling: 400 for invalid input, 503 for AI service unavailable, 500 for unexpected errors

    `GET /scripts/keywords` — List available segment keywords
    - Depends on `get_profile_context` for profile isolation
    - Fetches all unique keywords from `editai_segments` for current profile (same query as above)
    - Returns `{"keywords": ["keyword1", "keyword2", ...], "count": N}`
    - This lets the frontend show available keywords before generation

    2. Mount in `app/main.py`:
    - Add import: `from app.api.script_routes import router as script_router`
    - Add: `app.include_router(script_router, prefix="/api/v1", tags=["AI Script Generation"])`
    - Place after the tts_routes inclusion

    **Logging:**
    - Log script generation requests: `logger.info(f"[Profile {profile.profile_id}] Generating {variant_count} scripts with {provider}, {len(unique_keywords)} keywords")`
    - Log completion: `logger.info(f"[Profile {profile.profile_id}] Generated {len(scripts)} scripts successfully")`
  </action>
  <verify>
    - `python -c "from app.api.script_routes import router; print(f'Routes: {[r.path for r in router.routes]}')"` shows /generate and /keywords paths
    - `python -c "from app.main import app; routes = [r.path for r in app.routes]; print('scripts' in str(routes))"` confirms router is mounted
    - Start backend with `python run.py` and verify `/docs` shows the new script endpoints (manual check)
  </verify>
  <done>
    Script generation API is mounted at /api/v1/scripts with POST /generate and GET /keywords endpoints. Both endpoints are profile-scoped. Generate endpoint fetches segment keywords from DB and passes them to the AI script generator service.
  </done>
</task>

</tasks>

<verification>
1. Backend starts without errors: `python -c "from app.main import app; print('OK')"`
2. Script generator imports correctly: `python -c "from app.services.script_generator import get_script_generator; print('OK')"`
3. Script routes are mounted: `python -c "from app.main import app; print([r.path for r in app.routes if 'script' in str(r.path)])"`
4. Config has anthropic_api_key: `python -c "from app.config import get_settings; print(get_settings().anthropic_api_key)"`
5. requirements.txt includes anthropic
</verification>

<success_criteria>
- ScriptGenerator service supports Gemini and Claude providers
- API returns TTS-safe scripts (no emojis, no markdown, no stage directions)
- Segment keywords are fetched from DB and included in AI prompt
- Routes are profile-scoped via ProfileContext
- All imports and mounting work without errors
</success_criteria>

<output>
After completion, create `.planning/phases/14-ai-script-generation/14-01-SUMMARY.md`
</output>
