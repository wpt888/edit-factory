---
phase: 13-tts-based-subtitles
plan: 02
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - app/api/library_routes.py
autonomous: true

must_haves:
  truths:
    - "When TTS timestamps exist and no user-provided srt_content is present, SRT is auto-generated from timestamps during render"
    - "Auto-generated SRT feeds into existing subtitle_styler pipeline unchanged (shadow, glow, adaptive sizing all work)"
    - "When user has provided srt_content, that content is used instead of auto-generation (user content takes priority)"
    - "Subtitle sync with TTS audio is correct because timing comes directly from the same TTS generation"
  artifacts:
    - path: "app/api/library_routes.py"
      provides: "TTS-based subtitle generation wired into render pipeline"
      contains: "generate_srt_from_timestamps"
  key_links:
    - from: "app/api/library_routes.py"
      to: "app/services/tts_subtitle_generator.py"
      via: "import and call in _render_final_clip_task"
      pattern: "from app.services.tts_subtitle_generator import generate_srt_from_timestamps"
    - from: "app/api/library_routes.py (generated SRT)"
      to: "app/services/subtitle_styler.py"
      via: "srt_path passed to _render_with_preset -> build_subtitle_filter"
      pattern: "srt_path=srt_path"
---

<objective>
Wire the TTS subtitle generator into the render pipeline so SRT subtitles are auto-generated from ElevenLabs timestamps when no user-provided SRT content exists.

Purpose: Completes the TTS-based subtitle pipeline by connecting the generator service (Plan 01) to the render workflow. Users get perfectly synced subtitles automatically when TTS voiceover is generated, with all v3 styling (shadow, glow, adaptive sizing) applied without any changes to the styling system.

Output: Modified `app/api/library_routes.py` with auto-SRT generation in render task
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Plan 01 creates the generator service
@.planning/phases/13-tts-based-subtitles/13-01-SUMMARY.md
@app/api/library_routes.py
@app/services/subtitle_styler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire TTS subtitle generator into render pipeline</name>
  <files>app/api/library_routes.py</files>
  <action>
Modify `_render_final_clip_task()` in `app/api/library_routes.py` to auto-generate SRT from TTS timestamps when no user-provided SRT content exists.

**Location:** Between the TTS generation block (ends ~line 1866) and the SRT writing block (starts ~line 1909).

**Changes to make:**

1. **Add import** at top of file (with other service imports around line 24):
```python
from app.services.tts_subtitle_generator import generate_srt_from_timestamps
```

2. **Modify the SRT generation block** (currently lines 1909-1913). Replace:
```python
# 3. Generate SRT temporar daca avem continut
if content_data and content_data.get("srt_content"):
    srt_path = temp_dir / f"srt_{clip_id}.srt"
    with open(srt_path, "w", encoding="utf-8") as f:
        f.write(content_data["srt_content"])
```

With logic that:
a. First checks for user-provided `srt_content` (takes priority).
b. If no user SRT but `tts_timestamps` exist, auto-generate SRT from timestamps.
c. If neither exists, srt_path stays None (no subtitles).

```python
# 3. Generate SRT - user-provided takes priority, then auto-generate from TTS timestamps
if content_data and content_data.get("srt_content"):
    srt_path = temp_dir / f"srt_{clip_id}.srt"
    with open(srt_path, "w", encoding="utf-8") as f:
        f.write(content_data["srt_content"])
    logger.info(f"Using user-provided SRT for clip {clip_id}")
elif tts_timestamps:
    # Auto-generate SRT from TTS character-level timestamps (Phase 13)
    try:
        auto_srt = generate_srt_from_timestamps(tts_timestamps)
        if auto_srt:
            srt_path = temp_dir / f"srt_{clip_id}.srt"
            with open(srt_path, "w", encoding="utf-8") as f:
                f.write(auto_srt)
            logger.info(f"Auto-generated SRT from TTS timestamps for clip {clip_id}")
        else:
            logger.warning(f"TTS timestamps produced empty SRT for clip {clip_id}")
    except Exception as e:
        logger.warning(f"Failed to generate SRT from TTS timestamps: {e}")
```

3. **Ensure subtitle_settings default exists for auto-generated SRT.** The existing code at lines 1916-1920 injects Phase 11 settings only if `content_data.get("subtitle_settings")` exists. When SRT is auto-generated from timestamps, the user may not have set subtitle_settings. Add a default subtitle_settings dict if none exists but srt_path is set:

After the existing Phase 11 injection block (line 1920), add:
```python
# Ensure subtitle_settings exist when SRT is available (default styling for auto-generated subtitles)
if srt_path and (not content_data or not content_data.get("subtitle_settings")):
    if not content_data:
        content_data = {}
    content_data["subtitle_settings"] = {
        "fontSize": 48,
        "fontFamily": "Montserrat",
        "textColor": "#FFFFFF",
        "outlineColor": "#000000",
        "outlineWidth": 3,
        "positionY": 85,
        "shadowDepth": shadow_depth,
        "enableGlow": enable_glow,
        "glowBlur": glow_blur,
        "adaptiveSizing": adaptive_sizing
    }
    logger.info(f"Applied default subtitle styling for auto-generated SRT")
```

**Important:** The `tts_timestamps` variable is already set earlier in the function (line 1802, populated at line 1813). It's available at the SRT generation point. No need to fetch from Supabase again.

**Do NOT** change the `_render_with_preset()` function or `subtitle_styler.py` - the existing pipeline handles SRT files identically regardless of how they were generated.
  </action>
  <verify>
1. Check import exists: `grep "from app.services.tts_subtitle_generator import" app/api/library_routes.py`
2. Check auto-generation logic: `grep "generate_srt_from_timestamps" app/api/library_routes.py`
3. Check default subtitle settings: `grep "default subtitle styling" app/api/library_routes.py`
4. Start backend to verify no import errors: `cd "/mnt/c/OBSID SRL/n8n/edit_factory" && timeout 10 python -c "from app.api.library_routes import router; print('Import OK')" 2>&1 || echo "Check stderr for errors"`
  </verify>
  <done>
Render pipeline auto-generates SRT from TTS timestamps when no user SRT exists. User-provided SRT content takes priority. Default subtitle styling applied for auto-generated SRT. Import and code flow verified. The existing subtitle_styler pipeline (shadow, glow, adaptive sizing) works unchanged with auto-generated SRT.
  </done>
</task>

</tasks>

<verification>
1. Import chain: `library_routes.py` imports `generate_srt_from_timestamps` from `tts_subtitle_generator.py`
2. Priority logic: user SRT > auto-generated from timestamps > no subtitles
3. Default styling: auto-generated SRT gets sensible defaults if no subtitle_settings configured
4. No changes to subtitle_styler.py or _render_with_preset - existing pipeline reused unchanged
5. tts_timestamps variable correctly referenced (set earlier in same function scope)
</verification>

<success_criteria>
- SRT auto-generated from TTS timestamps when no user-provided SRT exists
- User-provided SRT content always takes priority over auto-generation
- Generated SRT feeds through existing v3 subtitle styling pipeline unchanged
- Default subtitle styling applied when no explicit settings exist
- No errors on backend import/startup
</success_criteria>

<output>
After completion, create `.planning/phases/13-tts-based-subtitles/13-02-SUMMARY.md`
</output>
