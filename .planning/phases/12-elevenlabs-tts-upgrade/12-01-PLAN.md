---
phase: 12-elevenlabs-tts-upgrade
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/services/tts/elevenlabs.py
  - app/services/elevenlabs_tts.py
  - app/config.py
autonomous: true

must_haves:
  truths:
    - "ElevenLabs service uses eleven_flash_v2_5 as default model"
    - "TTS audio is generated at 192kbps MP3 quality via output_format parameter"
    - "Character-level timestamps are retrieved from ElevenLabs /with-timestamps endpoint"
    - "Cost per 1k chars reflects flash v2.5 pricing (lower than multilingual v2)"
  artifacts:
    - path: "app/services/tts/elevenlabs.py"
      provides: "Updated ElevenLabsTTSService with timestamps and flash v2.5 default"
      contains: "generate_audio_with_timestamps"
    - path: "app/services/elevenlabs_tts.py"
      provides: "Updated legacy ElevenLabsTTS with flash v2.5 default and 192kbps output"
      contains: "eleven_flash_v2_5"
    - path: "app/config.py"
      provides: "Updated default model setting"
      contains: "eleven_flash_v2_5"
  key_links:
    - from: "app/services/tts/elevenlabs.py"
      to: "https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/with-timestamps"
      via: "httpx POST with output_format=mp3_44100_192"
      pattern: "with-timestamps"
---

<objective>
Upgrade both ElevenLabs TTS services (legacy `elevenlabs_tts.py` and new `tts/elevenlabs.py`) to use
`eleven_flash_v2_5` as default model, request 192kbps MP3 output quality, and add a new
`generate_audio_with_timestamps` method that calls the ElevenLabs `/with-timestamps` endpoint
to retrieve character-level timing data alongside the audio.

Purpose: Foundation for v4 script-first pipeline. Character timestamps enable Phase 13's
TTS-based subtitle generation without Whisper, and 192kbps quality ensures broadcast-ready audio.

Output:
- Updated `app/services/tts/elevenlabs.py` with `generate_audio_with_timestamps()` method
- Updated `app/services/elevenlabs_tts.py` (legacy) with flash v2.5 default + 192kbps
- Updated `app/config.py` default model
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@app/services/tts/elevenlabs.py
@app/services/tts/base.py
@app/services/elevenlabs_tts.py
@app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update config and legacy ElevenLabsTTS to flash v2.5 with 192kbps</name>
  <files>app/config.py, app/services/elevenlabs_tts.py</files>
  <action>
  1. In `app/config.py`, change the `elevenlabs_model` default from `"eleven_multilingual_v2"` to `"eleven_flash_v2_5"`.

  2. In `app/services/elevenlabs_tts.py`:
     - Update docstring to reflect new default model `eleven_flash_v2_5`.
     - Change the env fallback default from `"eleven_multilingual_v2"` to `"eleven_flash_v2_5"` in `__init__`.
     - In `generate_audio()`, add `output_format` parameter to the API request URL as a query param:
       Change the URL from `f"{self.BASE_URL}/text-to-speech/{self.voice_id}"` to
       `f"{self.BASE_URL}/text-to-speech/{self.voice_id}?output_format=mp3_44100_192"`.
       This tells ElevenLabs to return 192kbps 44.1kHz MP3 (instead of default 128kbps).
     - Update the `Accept` header to `"audio/mpeg"` (already correct, keep it).
     - Update cost logging: flash v2.5 costs ~$0.11 per 1000 chars (half of multilingual v2).
       Add a comment noting the cost difference but keep the tracker call as-is since the
       cost_tracker has its own pricing logic.

  NOTE: Do NOT change the `generate_audio_trimmed` or `process_video_with_tts` methods - they
  delegate to `generate_audio` and will inherit the changes automatically.
  </action>
  <verify>
  Run: `cd "/mnt/c/OBSID SRL/n8n/edit_factory" && python -c "from app.config import get_settings; s = get_settings(); assert s.elevenlabs_model == 'eleven_flash_v2_5', f'Expected eleven_flash_v2_5, got {s.elevenlabs_model}'; print('Config OK: default model is eleven_flash_v2_5')"` -- should print success.

  Run: `cd "/mnt/c/OBSID SRL/n8n/edit_factory" && python -c "from app.services.elevenlabs_tts import ElevenLabsTTS; print('Legacy import OK')"` -- should not raise syntax errors (will fail on missing API key, that's expected).

  Grep for `mp3_44100_192` in `app/services/elevenlabs_tts.py` to confirm output format is set.
  </verify>
  <done>
  - `app/config.py` has `elevenlabs_model: str = "eleven_flash_v2_5"` as default
  - Legacy `ElevenLabsTTS.generate_audio()` requests `output_format=mp3_44100_192` from ElevenLabs API
  - Default model fallback in legacy service is `eleven_flash_v2_5`
  </done>
</task>

<task type="auto">
  <name>Task 2: Add generate_audio_with_timestamps to ElevenLabsTTSService</name>
  <files>app/services/tts/elevenlabs.py</files>
  <action>
  1. Update `ElevenLabsTTSService.__init__` to default `model_id` to `"eleven_flash_v2_5"` (change the fallback from `"eleven_multilingual_v2"`).

  2. Update `cost_per_1k_chars` property to `0.11` (flash v2.5 is half the price of multilingual v2).

  3. Update `generate_audio()` method:
     - Add `output_format=mp3_44100_192` as query parameter to the URL to get 192kbps output.
       URL becomes: `f"{self.BASE_URL}/text-to-speech/{voice_id}?output_format=mp3_44100_192"`
     - Keep existing Accept header as `"audio/mpeg"`.

  4. Add new method `generate_audio_with_timestamps()`:

     ```python
     async def generate_audio_with_timestamps(
         self,
         text: str,
         voice_id: str,
         output_path: Path,
         model_id: Optional[str] = None,
         **kwargs
     ) -> Tuple[TTSResult, List[dict]]:
         """
         Generate audio with character-level timestamps from ElevenLabs.

         Uses the /text-to-speech/{voice_id}/with-timestamps endpoint.
         Returns both the audio file and character-level timing data.

         Args:
             text: Text to convert to speech
             voice_id: Voice identifier
             output_path: Where to save the audio file
             model_id: Optional model override (eleven_flash_v2_5, eleven_turbo_v2_5, eleven_multilingual_v2)
             **kwargs: Voice settings overrides

         Returns:
             Tuple of (TTSResult, timestamps_list) where timestamps_list is:
             [{"characters": ["H","e","l","l","o"], "character_start_times_seconds": [0.0, 0.05, ...],
               "character_end_times_seconds": [0.05, 0.1, ...]}]
         """
     ```

     Implementation:
     - URL: `f"{self.BASE_URL}/text-to-speech/{voice_id}/with-timestamps?output_format=mp3_44100_192"`
     - Headers: `{"Content-Type": "application/json", "xi-api-key": self.api_key}` (NOT `Accept: audio/mpeg` -- the with-timestamps endpoint returns JSON, not raw audio)
     - JSON body: `{"text": text, "model_id": model_id or self.model_id, "voice_settings": voice_settings}`
     - The response is JSON with structure:
       ```json
       {
         "audio_base64": "<base64-encoded-audio>",
         "alignment": {
           "characters": ["H", "e", "l", "l", "o", " ", "w", "o", "r", "l", "d"],
           "character_start_times_seconds": [0.0, 0.05, 0.09, ...],
           "character_end_times_seconds": [0.05, 0.09, 0.14, ...]
         }
       }
       ```
     - Decode `audio_base64` with `base64.b64decode()` and write to `output_path`.
     - Extract `alignment` dict from response JSON.
     - Calculate duration using `librosa.get_duration(path=str(output_path))`.
     - Calculate cost: `(len(text) / 1000.0) * self.cost_per_1k_chars`
     - Log cost via cost_tracker (same pattern as existing `generate_audio`).
     - Return `(TTSResult, alignment)` where alignment is the raw dict from the API response.

  5. Add `import base64` and `from typing import Tuple, List` at top of file (Tuple needed for return type).

  IMPORTANT: The `/with-timestamps` endpoint returns JSON (not streaming audio), so do NOT use
  `Accept: audio/mpeg` header. The audio is base64-encoded in the JSON response.
  </action>
  <verify>
  Run: `cd "/mnt/c/OBSID SRL/n8n/edit_factory" && python -c "
from app.services.tts.elevenlabs import ElevenLabsTTSService
import inspect
# Check method exists
assert hasattr(ElevenLabsTTSService, 'generate_audio_with_timestamps'), 'Missing method'
# Check signature
sig = inspect.signature(ElevenLabsTTSService.generate_audio_with_timestamps)
params = list(sig.parameters.keys())
assert 'text' in params, 'Missing text param'
assert 'voice_id' in params, 'Missing voice_id param'
assert 'model_id' in params, 'Missing model_id param'
print('ElevenLabsTTSService OK: generate_audio_with_timestamps exists with correct signature')
"` -- should print success.

  Grep for `with-timestamps` in `app/services/tts/elevenlabs.py` to confirm endpoint URL.
  Grep for `audio_base64` in `app/services/tts/elevenlabs.py` to confirm base64 decoding.
  Grep for `mp3_44100_192` in `app/services/tts/elevenlabs.py` to confirm 192kbps.
  </verify>
  <done>
  - `ElevenLabsTTSService` defaults to `eleven_flash_v2_5` model
  - `generate_audio()` requests 192kbps MP3 output via `output_format=mp3_44100_192`
  - New `generate_audio_with_timestamps()` method calls `/with-timestamps` endpoint
  - Method returns `(TTSResult, alignment_dict)` with character-level timing data
  - Cost per 1k chars updated to $0.11 for flash v2.5
  </done>
</task>

</tasks>

<verification>
1. Both ElevenLabs services default to `eleven_flash_v2_5` model
2. Both services request `mp3_44100_192` output format for 192kbps quality
3. `generate_audio_with_timestamps()` exists and calls `/with-timestamps` endpoint
4. Method returns alignment data with `characters`, `character_start_times_seconds`, `character_end_times_seconds`
5. Python imports work without syntax errors
6. Config default is `eleven_flash_v2_5`
</verification>

<success_criteria>
- TTS-01 SATISFIED: Default model is `eleven_flash_v2_5` in config and both services
- TTS-02 SATISFIED: 192kbps MP3 via `output_format=mp3_44100_192` query parameter
- TTS-03 PARTIALLY SATISFIED: `/with-timestamps` endpoint integrated, timestamps returned as data
  (Persistence handled in Plan 02)
</success_criteria>

<output>
After completion, create `.planning/phases/12-elevenlabs-tts-upgrade/12-01-SUMMARY.md`
</output>
