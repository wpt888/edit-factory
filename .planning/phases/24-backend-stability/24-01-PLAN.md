---
phase: 24-backend-stability
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/api/library_routes.py
  - app/db.py
requirements:
  - STAB-01
  - STAB-02
  - STAB-03
  - QUAL-04
autonomous: true

must_haves:
  truths:
    - "Generation progress survives a server restart — restarted server shows correct prior progress percentage"
    - "Project render locks are released after completion and never accumulate in _project_locks dict"
    - "A lock timeout returns 409 Conflict HTTP response instead of silently returning or logging a warning"
    - "cleanup_project_lock is called in every finally block that releases a lock"
  artifacts:
    - path: "app/api/library_routes.py"
      provides: "DB-backed progress tracking and lock lifecycle fixes"
      contains: "editai_generation_progress"
    - path: "app/db.py"
      provides: "Shared Supabase client singleton"
  key_links:
    - from: "app/api/library_routes.py::update_generation_progress"
      to: "Supabase editai_generation_progress table"
      via: "upsert on project_id"
      pattern: "upsert.*editai_generation_progress"
    - from: "app/api/library_routes.py::get_generation_progress"
      to: "Supabase editai_generation_progress table"
      via: "select fallback after in-memory miss"
      pattern: "select.*editai_generation_progress"
    - from: "app/api/library_routes.py::_render_final_clip_task"
      to: "409 Conflict response"
      via: "lock.acquire timeout failure"
      pattern: "409.*Conflict"
---

<objective>
Persist generation progress to Supabase so it survives server restarts, and fix the lock lifecycle so locks never accumulate and timeout produces a proper 409 Conflict response.

Purpose: Currently `_generation_progress` is an in-memory dict lost on restart, and locks silently fail or leak. This plan makes progress durable and locks predictable.
Output: DB-backed progress tracking, lock cleanup in all paths, 409 on lock timeout.
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@app/api/library_routes.py
@app/db.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DB table and persist generation progress</name>
  <files>app/api/library_routes.py</files>
  <action>
1. Create a Supabase migration for `editai_generation_progress` table via the Supabase MCP tool (apply_migration):
   ```sql
   CREATE TABLE IF NOT EXISTS editai_generation_progress (
     project_id TEXT PRIMARY KEY,
     percentage INTEGER NOT NULL DEFAULT 0,
     current_step TEXT NOT NULL DEFAULT '',
     estimated_remaining INTEGER,
     updated_at TIMESTAMPTZ NOT NULL DEFAULT now()
   );
   ```
   Enable RLS but add a permissive policy (same pattern as other editai_ tables).

2. Modify `update_generation_progress()` in library_routes.py to write to BOTH in-memory dict AND Supabase:
   - Keep the in-memory `_generation_progress[project_id]` write for fast polling
   - Add a Supabase upsert: `get_supabase().table("editai_generation_progress").upsert({"project_id": project_id, "percentage": percentage, "current_step": current_step, "estimated_remaining": estimated_remaining, "updated_at": datetime.now().isoformat()}).execute()`
   - Wrap the Supabase call in try/except — in-memory is primary, DB is durability layer
   - Log warning on DB failure, do NOT block the generation

3. Modify `get_generation_progress()` to fall back to DB when in-memory miss:
   - First check `_generation_progress.get(project_id)` (fast path)
   - If None, query Supabase: `get_supabase().table("editai_generation_progress").select("*").eq("project_id", project_id).maybe_single().execute()`
   - If DB result exists, populate in-memory cache and return it
   - If neither, return None (existing behavior)

4. Modify `clear_generation_progress()` to also delete from DB:
   - Keep the in-memory `del _generation_progress[project_id]`
   - Add Supabase delete: `get_supabase().table("editai_generation_progress").delete().eq("project_id", project_id).execute()`
   - Wrap in try/except, log warning on failure

5. In the `/projects/{project_id}/progress` endpoint (around line 355), the existing code already checks project status as fallback. No changes needed there — the improved `get_generation_progress()` now handles DB fallback automatically.
  </action>
  <verify>
Run the backend: `python run.py` — confirm no import errors. Check Supabase dashboard for the new `editai_generation_progress` table. Verify the migration was applied via `list_migrations` MCP tool.
  </verify>
  <done>
`update_generation_progress` writes to both memory and DB. `get_generation_progress` falls back to DB on memory miss. `clear_generation_progress` deletes from both. Server restart preserves progress for active jobs.
  </done>
</task>

<task type="auto">
  <name>Task 2: Fix lock lifecycle — cleanup, timeout 409, and QUAL-04 integration</name>
  <files>app/api/library_routes.py</files>
  <action>
1. **Lock timeout returns 409 Conflict (STAB-03):**
   In `_render_final_clip_task` (around line 1862), when `lock.acquire(timeout=300)` returns False, currently the code just logs a warning and updates clip status to "failed". Change this to ALSO raise an appropriate signal. Since this is a background task (not an endpoint directly), the 409 must be returned at the endpoint level. Modify the `render_final_clip` endpoint (around line 1720) to check if the project lock is currently held BEFORE dispatching the background task:
   ```python
   lock = get_project_lock(project_id)
   if not lock.acquire(blocking=False):
       lock_held = True
   else:
       lock.release()  # We just tested, release immediately
       lock_held = False
   if lock_held:
       raise HTTPException(status_code=409, detail="Project is currently being processed. Try again later.")
   ```
   Also do the same pre-check in `generate_from_segments` endpoint (around line 670) and `upload_and_generate` endpoint (around line 460) — if lock is already held, return 409 instead of silently queuing a task that will fail.

2. **Lock cleanup — never accumulate (STAB-02 + QUAL-04):**
   Audit ALL `finally:` blocks that call `lock.release()`:
   - `_generate_raw_clips_task` (line ~648): already calls `cleanup_project_lock` — GOOD
   - `_generate_from_segments_task` (line ~1205): already calls `cleanup_project_lock` — GOOD
   - `_render_final_clip_task` (line ~2162): already calls `cleanup_project_lock` — GOOD

   However, there's a subtle bug: if `lock.acquire(blocking=False)` returns False (line 563, 927), the function returns early WITHOUT releasing, which is correct. But `cleanup_project_lock` is never called either, so the lock dict entry remains even after the original holder finishes (since cleanup removes the key). This is fine — the original holder's finally block handles it.

   Add a periodic lock cleanup mechanism: add a helper function `_cleanup_stale_locks()` that iterates `_project_locks` and removes any lock that is NOT currently acquired (using `lock.acquire(blocking=False)` + immediate `lock.release()` pattern). Call this at the START of `get_project_lock()` if `len(_project_locks) > 50` to prevent unbounded growth.

   Also ensure `cleanup_project_lock` is called in the `cancel_generation` endpoint (line ~411) after clearing progress — currently it only calls `clear_generation_progress` but not `cleanup_project_lock`.

3. **Verify all lock paths are consistent:**
   - Every `lock.acquire()` has a matching `lock.release()` in a `finally` block
   - Every `lock.release()` is followed by `cleanup_project_lock()`
   - Every `clear_generation_progress()` call is present where progress was tracked
  </action>
  <verify>
Search for all `lock.acquire` calls in library_routes.py and verify each has a corresponding `lock.release()` + `cleanup_project_lock()` in a finally block. Search for `409` to confirm the new Conflict responses are in place. Test: start the server, note that `_project_locks` dict stays empty when no jobs are running.
  </verify>
  <done>
Lock timeout at endpoint level returns 409 Conflict. All lock paths have cleanup in finally blocks. Stale lock cleanup prevents unbounded dict growth. `cancel_generation` cleans up the lock.
  </done>
</task>

</tasks>

<verification>
1. Start server, trigger a generation, restart server mid-generation — after restart, GET /api/v1/library/projects/{id}/progress returns the last saved percentage (not 404)
2. Start server, trigger a render while another render is in progress on same project — second request returns 409 Conflict
3. After any generation completes, verify `_project_locks` dict is empty (add a temporary debug log or check via debugger)
4. Cancel a generation — verify both progress and lock are cleaned up
</verification>

<success_criteria>
- Generation progress persisted to editai_generation_progress table in Supabase
- Server restart preserves progress for active jobs
- Lock timeout returns 409 Conflict at endpoint level
- _project_locks dict never grows unbounded
- cleanup_project_lock called in every code path that releases a lock
</success_criteria>

<output>
After completion, create `.planning/phases/24-backend-stability/24-01-SUMMARY.md`
</output>
