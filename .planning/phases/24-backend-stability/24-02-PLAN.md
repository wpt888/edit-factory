---
phase: 24-backend-stability
plan: 02
type: execute
wave: 2
depends_on:
  - 24-01
files_modified:
  - app/api/library_routes.py
  - app/api/routes.py
  - app/services/elevenlabs_tts.py
requirements:
  - STAB-04
  - STAB-05
  - QUAL-02
autonomous: true

must_haves:
  truths:
    - "Uploading a file over 500 MB returns 413 Payload Too Large before the file is fully read"
    - "Sending malformed JSON in subtitle_settings form param returns 400 error with descriptive message"
    - "Legacy ElevenLabsTTS.generate_audio uses httpx.AsyncClient instead of sync httpx.Client"
  artifacts:
    - path: "app/api/library_routes.py"
      provides: "File size validation on upload endpoints"
      contains: "413"
    - path: "app/api/routes.py"
      provides: "JSON parse error handling returning 400"
      contains: "400.*JSON"
    - path: "app/services/elevenlabs_tts.py"
      provides: "Async ElevenLabs TTS client"
      contains: "async def generate_audio"
  key_links:
    - from: "app/api/library_routes.py::upload_and_generate"
      to: "413 Payload Too Large"
      via: "Content-Length header check before reading file"
      pattern: "413"
    - from: "app/api/routes.py::process_video"
      to: "400 Bad Request"
      via: "json.loads wrapped in try/except with HTTPException"
      pattern: "400.*Invalid.*JSON"
    - from: "app/services/elevenlabs_tts.py::generate_audio"
      to: "httpx.AsyncClient"
      via: "async with httpx.AsyncClient"
      pattern: "async with httpx.AsyncClient"
---

<objective>
Add file upload size validation (413 errors), JSON parse error handling (400 errors), and convert the legacy ElevenLabs TTS to async httpx.

Purpose: Prevent oversized uploads from consuming memory, surface malformed JSON as clear 400 errors instead of silent ignores or 500s, and modernize the legacy TTS client to match the async pattern already used in tts/elevenlabs.py.
Output: Validated upload endpoints, proper JSON error responses, async legacy TTS.
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-backend-stability/24-01-SUMMARY.md
@app/api/library_routes.py
@app/api/routes.py
@app/services/elevenlabs_tts.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: File upload size validation and JSON parse error handling</name>
  <files>app/api/library_routes.py, app/api/routes.py</files>
  <action>
1. **File upload size validation (STAB-05):**
   Add a reusable helper function at the top of library_routes.py (near the lock helpers):
   ```python
   MAX_UPLOAD_SIZE_MB = 500  # 500 MB limit for video uploads
   MAX_UPLOAD_SIZE_BYTES = MAX_UPLOAD_SIZE_MB * 1024 * 1024

   async def validate_upload_size(file: UploadFile, max_bytes: int = MAX_UPLOAD_SIZE_BYTES):
       """Validate file size before reading entire file into memory.
       Checks Content-Length header first (fast), then reads in chunks if needed."""
       # Fast path: check Content-Length header if available
       if hasattr(file, 'size') and file.size is not None:
           if file.size > max_bytes:
               raise HTTPException(
                   status_code=413,
                   detail=f"File too large. Maximum size is {max_bytes // (1024*1024)} MB."
               )
           return
       # Fallback: read first chunk to estimate (SpooledTemporaryFile)
       # For FastAPI/Starlette UploadFile, the file is already in memory or spooled
       # We can check the file position after seek to end
       file.file.seek(0, 2)  # Seek to end
       size = file.file.tell()
       file.file.seek(0)  # Reset to beginning
       if size > max_bytes:
           raise HTTPException(
               status_code=413,
               detail=f"File too large ({size // (1024*1024)} MB). Maximum size is {max_bytes // (1024*1024)} MB."
           )
   ```

   Add `await validate_upload_size(video)` call in these endpoints BEFORE `shutil.copyfileobj`:
   - `upload_and_generate` endpoint in library_routes.py (around line 489, before the `with open(final_video_path, "wb")` line)
   - `process_video` endpoint in routes.py (around line 592, before `shutil.copyfileobj`)
   - Also validate audio uploads in routes.py if present (around line 598)

   Also add the same helper (or import it) in routes.py. Since routes.py is a separate router, define the helper in a shared location or duplicate it (it's small). Preferred: define it in library_routes.py and import from there in routes.py, OR define it in a small `app/api/validators.py` utility file.

   Decision: Create `app/api/validators.py` with the helper, import in both route files.

2. **JSON parse error handling (STAB-04):**
   In routes.py `process_video` endpoint (around line 612), the `json.loads(subtitle_settings)` is already wrapped in try/except but catches `json.JSONDecodeError` and only logs a warning — it silently continues with `None`. Change this to raise a 400 error:
   ```python
   if subtitle_settings:
       try:
           parsed_subtitle_settings = json.loads(subtitle_settings)
       except json.JSONDecodeError as e:
           raise HTTPException(
               status_code=400,
               detail=f"Invalid JSON in subtitle_settings: {str(e)}"
           )
   ```

   Do the same for the second `json.loads(subtitle_settings)` occurrence in routes.py (around line 881).

   Search library_routes.py for any `json.loads` calls on user-provided data and apply the same pattern. Currently library_routes.py line 2246 has a `json.loads(result.stdout)` but that's parsing ffprobe output (internal), not user input — leave it.

   Also check if any endpoint accepts JSON strings in Form params that are silently parsed. The render endpoint in library_routes.py uses Form params with string types and parses booleans, but no JSON — OK.
  </action>
  <verify>
Test: `curl -X POST http://localhost:8000/api/v1/library/projects/{id}/upload -F "video=@large_file.mp4"` with a file > 500MB should return 413. Send a request with `subtitle_settings=not-json` to the process_video endpoint — should return 400 with "Invalid JSON" message, not a 500 or silent ignore.
  </verify>
  <done>
Files over 500 MB rejected with 413 Payload Too Large. Malformed JSON in form params rejected with 400 Bad Request and descriptive error message. No silent ignores or 500 errors for bad input.
  </done>
</task>

<task type="auto">
  <name>Task 2: Convert legacy ElevenLabsTTS to async httpx client</name>
  <files>app/services/elevenlabs_tts.py</files>
  <action>
1. **Convert `generate_audio` to async (QUAL-02):**
   The legacy `ElevenLabsTTS` class in `app/services/elevenlabs_tts.py` uses `httpx.Client` (sync) in its `generate_audio` method (line 116). The newer `ElevenLabsTTSService` in `app/services/tts/elevenlabs.py` already uses `httpx.AsyncClient` — follow that pattern.

   Changes to `app/services/elevenlabs_tts.py`:
   - Rename `generate_audio` to `async def generate_audio`
   - Change `with httpx.Client(timeout=120.0) as client:` to `async with httpx.AsyncClient(timeout=120.0) as client:`
   - Change `response = client.post(url, headers=headers, json=data)` to `response = await client.post(url, headers=headers, json=data)`
   - Change `except httpx.TimeoutException:` stays the same (works for both sync and async)

2. **Convert `add_audio_to_video` — check if it uses httpx:**
   Read the rest of `elevenlabs_tts.py` to check if `add_audio_to_video` or other methods use httpx. If they only use subprocess/ffmpeg, leave them sync. Only convert HTTP-calling methods to async.

3. **Update callers:**
   Search for all callers of `ElevenLabsTTS.generate_audio` (the legacy class, not the new ElevenLabsTTSService):
   - `grep -r "generate_audio" app/` to find callers
   - Any caller that was `tts.generate_audio(...)` must become `await tts.generate_audio(...)`
   - If the caller is a sync function, it needs to become async too (or use `asyncio.run()` if in a thread context)
   - Background tasks in FastAPI can be async, so this should be straightforward

   NOTE: The legacy `ElevenLabsTTS` class may not be actively used anymore — the newer `ElevenLabsTTSService` in `tts/elevenlabs.py` might have replaced it. Verify by searching for imports of the legacy class. If it's unused, just convert it and note that in the summary. If it IS used, update the callers.

4. **Preserve the `get_elevenlabs_tts()` singleton factory** — just make sure it still works after the async conversion.
  </action>
  <verify>
`grep -n "httpx.Client\b" app/services/elevenlabs_tts.py` should return 0 matches (only AsyncClient). `grep -n "async def generate_audio" app/services/elevenlabs_tts.py` should return 1 match. Start the server, verify no import errors.
  </verify>
  <done>
Legacy ElevenLabsTTS.generate_audio uses httpx.AsyncClient. All callers updated to await. No sync httpx.Client usage remains in elevenlabs_tts.py.
  </done>
</task>

</tasks>

<verification>
1. Upload a 1 MB video — succeeds normally (no false positive)
2. Upload a file with spoofed Content-Length > 500 MB OR an actual large file — returns 413 immediately
3. Send `subtitle_settings=}{broken` to process_video — returns 400 with JSON error detail
4. Start server, generate TTS — verify async client is used (check logs for "Generating TTS for X characters...")
5. No 500 errors for any of the above scenarios
</verification>

<success_criteria>
- File upload validation rejects files > 500 MB with 413 Payload Too Large
- Malformed JSON in subtitle_settings returns 400 Bad Request with descriptive error
- Legacy ElevenLabsTTS uses async httpx.AsyncClient
- All callers of generate_audio properly await the async call
- No regressions in normal upload/render flow
</success_criteria>

<output>
After completion, create `.planning/phases/24-backend-stability/24-02-SUMMARY.md`
</output>
