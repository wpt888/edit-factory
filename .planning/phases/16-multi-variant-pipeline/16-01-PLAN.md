---
phase: 16-multi-variant-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/api/pipeline_routes.py
  - app/main.py
autonomous: true
must_haves:
  truths:
    - "POST /api/v1/pipeline/generate accepts idea, context, variant_count, provider and returns pipeline_id + N scripts"
    - "POST /api/v1/pipeline/preview/{pipeline_id}/{variant_index} runs assembly preview for one variant and returns match data"
    - "POST /api/v1/pipeline/render accepts pipeline_id + list of variant indices and starts N background render jobs"
    - "GET /api/v1/pipeline/status/{pipeline_id} returns status of all variants including per-job progress and final video paths"
  artifacts:
    - path: "app/api/pipeline_routes.py"
      provides: "Multi-variant pipeline API endpoints"
      exports: ["router"]
    - path: "app/main.py"
      provides: "Pipeline router registration"
      contains: "pipeline_router"
  key_links:
    - from: "app/api/pipeline_routes.py"
      to: "app/services/script_generator.py"
      via: "get_script_generator().generate_scripts()"
      pattern: "get_script_generator"
    - from: "app/api/pipeline_routes.py"
      to: "app/services/assembly_service.py"
      via: "get_assembly_service().preview_matches() and assemble_and_render()"
      pattern: "get_assembly_service"
    - from: "app/main.py"
      to: "app/api/pipeline_routes.py"
      via: "include_router"
      pattern: "pipeline_router"
---

<objective>
Create backend API that orchestrates the end-to-end multi-variant pipeline: generate N scripts from an idea, preview segment matching per variant, and batch-render selected variants with job progress tracking.

Purpose: This is the glue layer connecting Phase 14 (script generation) and Phase 15 (assembly) into a single coordinated workflow. No new business logic needed — just orchestration endpoints and in-memory pipeline state.

Output: `app/api/pipeline_routes.py` with 4 endpoints, registered in `app/main.py`.
</objective>

<execution_context>
@/home/ukfdb/.claude/get-shit-done/workflows/execute-plan.md
@/home/ukfdb/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-ai-script-generation/14-01-SUMMARY.md
@.planning/phases/15-script-to-video-assembly/15-01-SUMMARY.md

# Key source files to reference:
@app/services/script_generator.py
@app/services/assembly_service.py
@app/api/script_routes.py
@app/api/assembly_routes.py
@app/main.py
@app/api/auth.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pipeline routes with 4 endpoints</name>
  <files>app/api/pipeline_routes.py</files>
  <action>
Create `app/api/pipeline_routes.py` with the following structure:

**In-memory state:**
- `_pipelines: Dict[str, dict]` — keyed by pipeline_id, stores: scripts list, provider, idea, variant_count, previews dict, render_jobs dict, created_at

**Pydantic models:**
- `PipelineGenerateRequest(idea: str, context: str = "", variant_count: int = 3, provider: str = "gemini")`
- `PipelineGenerateResponse(pipeline_id: str, scripts: List[str], provider: str, keyword_count: int, variant_count: int)`
- `PipelinePreviewResponse` — reuse same structure as AssemblyPreviewResponse (audio_duration, srt_content, matches, total_phrases, matched_count, unmatched_count)
- `VariantStatus(variant_index: int, status: str, progress: int, current_step: str, final_video_path: Optional[str], error: Optional[str])`
- `PipelineRenderRequest(variant_indices: List[int], preset_name: str = "TikTok", font_size: int = 48, font_family: str = "Montserrat", text_color: str = "#FFFFFF", outline_color: str = "#000000", outline_width: int = 3, position_y: int = 85, shadow_depth: int = 0, enable_glow: bool = False, glow_blur: int = 0, adaptive_sizing: bool = False, enable_denoise: bool = False, denoise_strength: float = 2.0, enable_sharpen: bool = False, sharpen_amount: float = 0.5, enable_color: bool = False, brightness: float = 0.0, contrast: float = 1.0, saturation: float = 1.0, elevenlabs_model: str = "eleven_flash_v2_5")`
- `PipelineRenderResponse(pipeline_id: str, rendering_variants: List[int], total_variants: int)`
- `PipelineStatusResponse(pipeline_id: str, scripts: List[str], provider: str, variants: List[VariantStatus])`

**Endpoints (router prefix="/pipeline", tags=["Multi-Variant Pipeline"]):**

1. `POST /generate` — Auth required (get_profile_context)
   - Validate input (variant_count 1-10, provider in [gemini, claude], idea non-empty)
   - Fetch keywords from editai_segments (same pattern as script_routes.py)
   - Call `get_script_generator().generate_scripts(idea, context, keywords, variant_count, provider)`
   - Generate pipeline_id (uuid4)
   - Store pipeline in _pipelines dict: {pipeline_id, scripts, provider, idea, context, variant_count, keyword_count, previews: {}, render_jobs: {}, created_at}
   - Return PipelineGenerateResponse

2. `POST /preview/{pipeline_id}/{variant_index}` — Auth required
   - Validate pipeline_id exists in _pipelines
   - Validate variant_index in range [0, len(scripts)-1]
   - Get script text from _pipelines[pipeline_id]["scripts"][variant_index]
   - Call `get_assembly_service().preview_matches(script_text, profile.profile_id, elevenlabs_model)` (elevenlabs_model from query param, default "eleven_flash_v2_5")
   - Store preview result in _pipelines[pipeline_id]["previews"][variant_index]
   - Return PipelinePreviewResponse (same shape as assembly preview)

3. `POST /render/{pipeline_id}` — Auth required
   - Validate pipeline_id exists
   - Validate all variant_indices are in range
   - Fetch preset from editai_export_presets (same pattern as assembly_routes.py render)
   - For each variant_index in request.variant_indices:
     - Initialize render job entry in _pipelines[pipeline_id]["render_jobs"][variant_index]
     - Create async background task (via BackgroundTasks) that:
       - Updates progress in render_jobs dict (same pattern as assembly_routes do_assembly)
       - Calls `get_assembly_service().assemble_and_render(script_text, profile_id, preset_data, subtitle_settings, ...)`
       - On success: updates status="completed", stores final_video_path
       - On failure: updates status="failed", stores error
   - Return PipelineRenderResponse

4. `GET /status/{pipeline_id}` — No auth (pipeline_id is the secret, same pattern as assembly/status)
   - Validate pipeline_id exists
   - Build variants list with VariantStatus for each variant (including those not yet rendered)
   - Return PipelineStatusResponse

**Important patterns to follow:**
- Lazy Supabase initialization (get_supabase singleton) — same as script_routes.py and assembly_routes.py
- ProfileContext auth via Depends(get_profile_context) on generate/preview/render endpoints
- Status endpoint is public (pipeline_id is the secret) — same pattern as assembly status
- Background task pattern via BackgroundTasks — same as assembly_routes.py render endpoint
- In-memory _pipelines dict for state (consistent with _assembly_jobs and _generation_progress patterns)

**Do NOT:**
- Create any new service file (reuse existing script_generator and assembly_service)
- Modify any existing service
- Add new dependencies
  </action>
  <verify>
Run: `python -m py_compile app/api/pipeline_routes.py`
Run: `python -c "from app.api.pipeline_routes import router; print(f'Routes: {len(router.routes)}')"` — expect 4 routes
  </verify>
  <done>
pipeline_routes.py exists with 4 endpoints (generate, preview, render, status), all using existing services via get_script_generator() and get_assembly_service(), with in-memory pipeline state tracking.
  </done>
</task>

<task type="auto">
  <name>Task 2: Register pipeline router in main.py</name>
  <files>app/main.py</files>
  <action>
Add to app/main.py:

1. Import: `from app.api.pipeline_routes import router as pipeline_router`
2. Register: `app.include_router(pipeline_router, prefix="/api/v1", tags=["Multi-Variant Pipeline"])`

Place the import after the assembly_router import line.
Place the include_router after the assembly_router include_router line.

**Do NOT** modify any other part of main.py.
  </action>
  <verify>
Run: `python -m py_compile app/main.py`
Run: `python -c "from app.main import app; routes = [r.path for r in app.routes]; pipeline_routes = [r for r in routes if 'pipeline' in r]; print(pipeline_routes)"` — expect 4 pipeline routes
  </verify>
  <done>
pipeline_router is imported and registered in main.py, making all 4 pipeline endpoints available under /api/v1/pipeline/*.
  </done>
</task>

</tasks>

<verification>
1. `python -m py_compile app/api/pipeline_routes.py` — no syntax errors
2. `python -m py_compile app/main.py` — no syntax errors
3. `python -c "from app.api.pipeline_routes import router; print(len(router.routes))"` — outputs 4
4. `python -c "from app.main import app; routes = [r.path for r in app.routes]; print([r for r in routes if 'pipeline' in r])"` — shows 4 pipeline routes
</verification>

<success_criteria>
- pipeline_routes.py creates 4 endpoints: generate, preview, render, status
- All endpoints reuse existing services (no new business logic files)
- In-memory _pipelines dict tracks pipeline state across endpoints
- Router registered in main.py and accessible under /api/v1/pipeline
- Background render jobs track progress per variant independently
</success_criteria>

<output>
After completion, create `.planning/phases/16-multi-variant-pipeline/16-01-SUMMARY.md`
</output>
